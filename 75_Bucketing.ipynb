{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZMCybUH+GkgK+jlYSlLHp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keertu24/databricks_1/blob/main/75_Bucketing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XVOnYRY9-lsF"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"ColabSpark\") \\\n",
        "    .getOrCreate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check If Buckting Enabled"
      ],
      "metadata": {
        "id": "fnnMlDrQ_fwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.conf.get(\"spark.sql.sources.bucketing.enabled\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3aBBY_cG_Mu4",
        "outputId": "ae014cbc-107a-4d83-cb6b-f64adb167753"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'true'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create Sample Data for Demo"
      ],
      "metadata": {
        "id": "9uNLgc-3_Yg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col,rand\n",
        "df=spark.range(1,10000000,1,10).select(col(\"id\").alias(\"PK\"),rand(10).alias(\"Attribute\"))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9o3XB9M_lY-",
        "outputId": "ef0841af-844b-4f78-e4a0-81eabd3f298e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------+\n",
            "| PK|          Attribute|\n",
            "+---+-------------------+\n",
            "|  1| 0.1709497137955568|\n",
            "|  2| 0.8051143958005459|\n",
            "|  3| 0.5775925576589018|\n",
            "|  4| 0.9476047869880925|\n",
            "|  5|    0.2093704977577|\n",
            "|  6|0.36664222617947817|\n",
            "|  7| 0.8078688178371882|\n",
            "|  8| 0.7135143433452461|\n",
            "|  9| 0.7195325566306053|\n",
            "| 10|0.31335292311175456|\n",
            "| 11| 0.8062503712025726|\n",
            "| 12|0.10814914646176654|\n",
            "| 13| 0.3362232980701172|\n",
            "| 14| 0.8133304803837667|\n",
            "| 15|0.47649428738170896|\n",
            "| 16|  0.524728096293865|\n",
            "| 17| 0.9701253460019921|\n",
            "| 18| 0.6232167713919952|\n",
            "| 19| 0.5089687568245219|\n",
            "| 20| 0.5467504094508642|\n",
            "+---+-------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create Non-Buckted Table"
      ],
      "metadata": {
        "id": "ZIakG0qhtQMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"nonbucketedTable\")"
      ],
      "metadata": {
        "id": "taTBsCV4FdY3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create Buckted Table"
      ],
      "metadata": {
        "id": "MX-YBHZYtefO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.format(\"parquet\").bucketBy(10,\"PK\").mode(\"overwrite\").saveAsTable(\"bucktedTable\")"
      ],
      "metadata": {
        "id": "lXVPTIKutX4m"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=spark.table(\"bucktedTable\")\n",
        "df2=spark.table(\"bucktedTable\")\n",
        "\n",
        "df3=spark.table(\"nonbucketedTable\")\n",
        "df4=spark.table(\"nonbucketedTable\")"
      ],
      "metadata": {
        "id": "OjNLONjy2SuJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Broadcast Join by Deafult if less than 10 mB"
      ],
      "metadata": {
        "id": "uK_W8G1-2qQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3.join(df4,\"PK\",\"inner\").explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLCSdTNs2oD9",
        "outputId": "ece33602-0c13-4999-cc13-19c7d709e2dd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "*(5) Project [PK#43L, Attribute#44, Attribute#46]\n",
            "+- *(5) SortMergeJoin [PK#43L], [PK#45L], Inner\n",
            "   :- *(2) Sort [PK#43L ASC NULLS FIRST], false, 0\n",
            "   :  +- Exchange hashpartitioning(PK#43L, 200), ENSURE_REQUIREMENTS, [plan_id=566]\n",
            "   :     +- *(1) Filter isnotnull(PK#43L)\n",
            "   :        +- *(1) ColumnarToRow\n",
            "   :           +- FileScan parquet spark_catalog.default.nonbucketedtable[PK#43L,Attribute#44] Batched: true, DataFilters: [isnotnull(PK#43L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/spark-warehouse/nonbucketedtable], PartitionFilters: [], PushedFilters: [IsNotNull(PK)], ReadSchema: struct<PK:bigint,Attribute:double>\n",
            "   +- *(4) Sort [PK#45L ASC NULLS FIRST], false, 0\n",
            "      +- ReusedExchange [PK#45L, Attribute#46], Exchange hashpartitioning(PK#43L, 200), ENSURE_REQUIREMENTS, [plan_id=566]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Disable Broadcast Join"
      ],
      "metadata": {
        "id": "aNe2_2Lo29_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\",-1)\n",
        "spark.conf.set(\"spark.sql.adaptive.enabled\",False)"
      ],
      "metadata": {
        "id": "g3tvPz8u28MP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.join(df4,\"PK\",\"inner\").explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juAKyl773Qjk",
        "outputId": "4557c2ee-d1e5-4b29-df1e-237aed8c7503"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "*(5) Project [PK#43L, Attribute#44, Attribute#50]\n",
            "+- *(5) SortMergeJoin [PK#43L], [PK#49L], Inner\n",
            "   :- *(2) Sort [PK#43L ASC NULLS FIRST], false, 0\n",
            "   :  +- Exchange hashpartitioning(PK#43L, 200), ENSURE_REQUIREMENTS, [plan_id=653]\n",
            "   :     +- *(1) Filter isnotnull(PK#43L)\n",
            "   :        +- *(1) ColumnarToRow\n",
            "   :           +- FileScan parquet spark_catalog.default.nonbucketedtable[PK#43L,Attribute#44] Batched: true, DataFilters: [isnotnull(PK#43L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/spark-warehouse/nonbucketedtable], PartitionFilters: [], PushedFilters: [IsNotNull(PK)], ReadSchema: struct<PK:bigint,Attribute:double>\n",
            "   +- *(4) Sort [PK#49L ASC NULLS FIRST], false, 0\n",
            "      +- ReusedExchange [PK#49L, Attribute#50], Exchange hashpartitioning(PK#43L, 200), ENSURE_REQUIREMENTS, [plan_id=653]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.join(df4,\"PK\",\"inner\").count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfZydcZ57YbA",
        "outputId": "a0de307d-1358-4a85-9e7a-7cc5c9fd70e3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9999999"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Non bucketed to bucketed join. One side would be shuffled"
      ],
      "metadata": {
        "id": "4KhW6QQl6jm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3.join(df2,\"PK\",\"inner\").explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbXmEmm26IWy",
        "outputId": "b75116e3-0455-4adb-c309-45d7cd4c9725"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "*(4) Project [PK#43L, Attribute#44, Attribute#42]\n",
            "+- *(4) SortMergeJoin [PK#43L], [PK#41L], Inner\n",
            "   :- *(2) Sort [PK#43L ASC NULLS FIRST], false, 0\n",
            "   :  +- Exchange hashpartitioning(PK#43L, 10), ENSURE_REQUIREMENTS, [plan_id=739]\n",
            "   :     +- *(1) Filter isnotnull(PK#43L)\n",
            "   :        +- *(1) ColumnarToRow\n",
            "   :           +- FileScan parquet spark_catalog.default.nonbucketedtable[PK#43L,Attribute#44] Batched: true, DataFilters: [isnotnull(PK#43L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/spark-warehouse/nonbucketedtable], PartitionFilters: [], PushedFilters: [IsNotNull(PK)], ReadSchema: struct<PK:bigint,Attribute:double>\n",
            "   +- *(3) Sort [PK#41L ASC NULLS FIRST], false, 0\n",
            "      +- *(3) Filter isnotnull(PK#41L)\n",
            "         +- *(3) ColumnarToRow\n",
            "            +- FileScan parquet spark_catalog.default.bucktedtable[PK#41L,Attribute#42] Batched: true, Bucketed: true, DataFilters: [isnotnull(PK#41L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/spark-warehouse/bucktedtable], PartitionFilters: [], PushedFilters: [IsNotNull(PK)], ReadSchema: struct<PK:bigint,Attribute:double>, SelectedBucketsCount: 10 out of 10\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.join(df2,\"PK\",\"inner\").count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-HLE7l37cLu",
        "outputId": "3be2f587-c03c-4ab0-8ff5-96923b1da067"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9999999"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Both Bucketed"
      ],
      "metadata": {
        "id": "jyU0jQZf6t4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.join(df2,\"PK\",\"inner\").explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_UBTPip6V08",
        "outputId": "4fa023b1-0e1c-4296-dac7-362db4d2ed2f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "*(3) Project [PK#41L, Attribute#42, Attribute#54]\n",
            "+- *(3) SortMergeJoin [PK#41L], [PK#53L], Inner\n",
            "   :- *(1) Sort [PK#41L ASC NULLS FIRST], false, 0\n",
            "   :  +- *(1) Filter isnotnull(PK#41L)\n",
            "   :     +- *(1) ColumnarToRow\n",
            "   :        +- FileScan parquet spark_catalog.default.bucktedtable[PK#41L,Attribute#42] Batched: true, Bucketed: true, DataFilters: [isnotnull(PK#41L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/spark-warehouse/bucktedtable], PartitionFilters: [], PushedFilters: [IsNotNull(PK)], ReadSchema: struct<PK:bigint,Attribute:double>, SelectedBucketsCount: 10 out of 10\n",
            "   +- *(2) Sort [PK#53L ASC NULLS FIRST], false, 0\n",
            "      +- *(2) Filter isnotnull(PK#53L)\n",
            "         +- *(2) ColumnarToRow\n",
            "            +- FileScan parquet spark_catalog.default.bucktedtable[PK#53L,Attribute#54] Batched: true, Bucketed: true, DataFilters: [isnotnull(PK#53L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/spark-warehouse/bucktedtable], PartitionFilters: [], PushedFilters: [IsNotNull(PK)], ReadSchema: struct<PK:bigint,Attribute:double>, SelectedBucketsCount: 10 out of 10\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.join(df2,\"PK\",\"inner\").count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_bNxW2v7ixN",
        "outputId": "d2235ded-20c9-462e-d669-6d5da9ccbd4e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9999999"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}