{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5jFznqQuJjlp252yNv798",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keertu24/databricks_1/blob/main/72_Explain_Plan_Google_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"ColabSpark\") \\\n",
        "    .getOrCreate()\n"
      ],
      "metadata": {
        "id": "a9cysq1oLJ0d"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB4BK6ZeKufs",
        "outputId": "f9b38a1e-f201-4531-d679-6d8f9f89ffa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+----------+------+\n",
            "|emp_id|   name|department|salary|\n",
            "+------+-------+----------+------+\n",
            "|     1|  James|     Sales|  3000|\n",
            "|     2|Michael|     Sales|  4600|\n",
            "|     3| Robert|     Sales|  4100|\n",
            "|     4|  Maria|   Finance|  3000|\n",
            "|     5|  Scott|   Finance|  3300|\n",
            "|     6|    Jen|   Finance|  3900|\n",
            "|     7|   Jeff| Marketing|  3000|\n",
            "|     8|  Kumar| Marketing|  2000|\n",
            "|     9|   Sara| Marketing|  3800|\n",
            "+------+-------+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "employees_data = [\n",
        "    (1, \"James\",   \"Sales\",      3000),\n",
        "    (2, \"Michael\", \"Sales\",      4600),\n",
        "    (3, \"Robert\",  \"Sales\",      4100),\n",
        "    (4, \"Maria\",   \"Finance\",    3000),\n",
        "    (5, \"Scott\",   \"Finance\",    3300),\n",
        "    (6, \"Jen\",     \"Finance\",    3900),\n",
        "    (7, \"Jeff\",    \"Marketing\",  3000),\n",
        "    (8, \"Kumar\",   \"Marketing\",  2000),\n",
        "    (9, \"Sara\",    \"Marketing\",  3800)\n",
        "]\n",
        "\n",
        "employees_cols = [\"emp_id\", \"name\", \"department\", \"salary\"]\n",
        "df_emp = spark.createDataFrame(employees_data, employees_cols)\n",
        "df_emp.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "department_data = [\n",
        "    (\"Sales\",     \"Region_A\"),\n",
        "    (\"Finance\",   \"Region_B\"),\n",
        "    (\"Marketing\", \"Region_C\"),\n",
        "    (\"HR\",        \"Region_D\")   # unused, forces LEFT JOIN logic\n",
        "]\n",
        "\n",
        "department_cols = [\"department\", \"region\"]\n",
        "df_dept = spark.createDataFrame(department_data, department_cols)\n",
        "df_dept.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v1c0qH9LW-a",
        "outputId": "ca204c29-69ca-4e09-f1aa-1b7300092b84"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+\n",
            "|department|  region|\n",
            "+----------+--------+\n",
            "|     Sales|Region_A|\n",
            "|   Finance|Region_B|\n",
            "| Marketing|Region_C|\n",
            "|        HR|Region_D|\n",
            "+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_join = df_emp.join(df_dept, \"department\", \"left\")\n",
        "df_join.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdgKGOHkLZ_T",
        "outputId": "b52ca436-299e-4a8c-9acc-539eee11644e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+-------+------+--------+\n",
            "|department|emp_id|   name|salary|  region|\n",
            "+----------+------+-------+------+--------+\n",
            "|     Sales|     1|  James|  3000|Region_A|\n",
            "|     Sales|     2|Michael|  4600|Region_A|\n",
            "|     Sales|     3| Robert|  4100|Region_A|\n",
            "|   Finance|     4|  Maria|  3000|Region_B|\n",
            "|   Finance|     5|  Scott|  3300|Region_B|\n",
            "|   Finance|     6|    Jen|  3900|Region_B|\n",
            "| Marketing|     7|   Jeff|  3000|Region_C|\n",
            "| Marketing|     8|  Kumar|  2000|Region_C|\n",
            "| Marketing|     9|   Sara|  3800|Region_C|\n",
            "+----------+------+-------+------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum as sum_, avg, count, max as max_\n",
        "\n",
        "df_agg = (\n",
        "    df_join.groupBy(\"region\")\n",
        "           .agg(\n",
        "               count(\"*\").alias(\"employee_count\"),\n",
        "               sum_(\"salary\").alias(\"total_salary\"),\n",
        "               avg(\"salary\").alias(\"avg_salary\"),\n",
        "               max_(\"salary\").alias(\"max_salary\")\n",
        "           )\n",
        ")\n",
        "\n",
        "df_agg.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIkYunrVLc5i",
        "outputId": "bb365c70-bb51-4051-dc4c-3d2ab880c59d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------+------------+------------------+----------+\n",
            "|  region|employee_count|total_salary|        avg_salary|max_salary|\n",
            "+--------+--------------+------------+------------------+----------+\n",
            "|Region_C|             3|        8800|2933.3333333333335|      3800|\n",
            "|Region_A|             3|       11700|            3900.0|      4600|\n",
            "|Region_B|             3|       10200|            3400.0|      3900|\n",
            "+--------+--------------+------------+------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = df_agg.orderBy(\"total_salary\", ascending=False)\n",
        "df_final.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TansXY18Lgla",
        "outputId": "1ad7ee71-21d1-496f-903a-e9a947d9c953"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------+------------+------------------+----------+\n",
            "|  region|employee_count|total_salary|        avg_salary|max_salary|\n",
            "+--------+--------------+------------+------------------+----------+\n",
            "|Region_A|             3|       11700|            3900.0|      4600|\n",
            "|Region_B|             3|       10200|            3400.0|      3900|\n",
            "|Region_C|             3|        8800|2933.3333333333335|      3800|\n",
            "+--------+--------------+------------+------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.explain()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cyp2qS4jLlfR",
        "outputId": "d679c410-c5e8-4760-a991-20e2a31e87d1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Sort [total_salary#43L DESC NULLS LAST], true, 0\n",
            "   +- Exchange rangepartitioning(total_salary#43L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=670]\n",
            "      +- HashAggregate(keys=[region#18], functions=[count(1), sum(salary#3L), avg(salary#3L), max(salary#3L)])\n",
            "         +- Exchange hashpartitioning(region#18, 200), ENSURE_REQUIREMENTS, [plan_id=667]\n",
            "            +- HashAggregate(keys=[region#18], functions=[partial_count(1), partial_sum(salary#3L), partial_avg(salary#3L), partial_max(salary#3L)])\n",
            "               +- Project [salary#3L, region#18]\n",
            "                  +- SortMergeJoin [department#2], [department#17], LeftOuter\n",
            "                     :- Sort [department#2 ASC NULLS FIRST], false, 0\n",
            "                     :  +- Exchange hashpartitioning(department#2, 200), ENSURE_REQUIREMENTS, [plan_id=659]\n",
            "                     :     +- Project [department#2, salary#3L]\n",
            "                     :        +- Scan ExistingRDD[emp_id#0L,name#1,department#2,salary#3L]\n",
            "                     +- Sort [department#17 ASC NULLS FIRST], false, 0\n",
            "                        +- Exchange hashpartitioning(department#17, 200), ENSURE_REQUIREMENTS, [plan_id=660]\n",
            "                           +- Filter isnotnull(department#17)\n",
            "                              +- Scan ExistingRDD[department#17,region#18]\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}